{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "<class 'str'>\n",
      "<class 'int'>\n",
      "Hello\n",
      "<class 'str'>\n",
      "<class 'int'>\n",
      "['F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/81_left.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/81_right.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/84_left.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/84_right.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/99_right.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/99_left.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/104_left.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/104_right.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/111_left.jpeg', 'F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/111_right.jpeg']\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnimplementedError'>, Cast string to int32 is not supported\n",
      "\t [[Node: Cast_9 = Cast[DstT=DT_INT32, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Cast_9/x)]]\n",
      "done!\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Cast string to int32 is not supported\n\t [[Node: Cast_9 = Cast[DstT=DT_INT32, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Cast_9/x)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-7a19521c881f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, sess, enqueue_op, coord)\u001b[0m\n\u001b[0;32m    236\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m           \u001b[0menqueue_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue_closed_exception_types\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[1;31m# This exception indicates that a queue was closed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_single_operation_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m           tf_session.TF_Run(self._session, None, {}, [],\n\u001b[1;32m-> 1063\u001b[1;33m                             target_list_as_strings, status, None)\n\u001b[0m\u001b[0;32m   1064\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    464\u001b[0m           \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Cast string to int32 is not supported\n\t [[Node: Cast_9 = Cast[DstT=DT_INT32, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Cast_9/x)]]"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "#%%\n",
    "\n",
    "# you need to change this to your data directory\n",
    "train_dir ='F:/Udacity ML/git/udacity-capstone'\n",
    "\n",
    "def get_files():\n",
    "    '''\n",
    "    Args:\n",
    "        file_dir: file directory\n",
    "    Returns:\n",
    "        list of images and labels\n",
    "    '''\n",
    "    print(tf.__version__)\n",
    "    \n",
    "    #cats = []\n",
    "    #label_cats = []\n",
    "    #dogs = []\n",
    "    #label_dogs = []\n",
    "    #for file in os.listdir(file_dir):\n",
    "     #   name = file.split(sep='.')\n",
    "        #if name[0]=='cat':\n",
    "            #cats.append(file_dir + file)\n",
    "            #label_cats.append(0)\n",
    "        #else:\n",
    "            #dogs.append(file_dir + file)\n",
    "            #label_dogs.append(1)\n",
    "    #print('There are %d cats\\nThere are %d dogs' %(len(cats), len(dogs)))\n",
    "    \n",
    "    #image_list = np.hstack((cats, dogs))\n",
    "    #label_list = np.hstack((label_cats, label_dogs))\n",
    "    \n",
    "    #temp = np.array([image_list, label_list])\n",
    "    #temp = temp.transpose()\n",
    "    #np.random.shuffle(temp)\n",
    "    \n",
    "    #image_list = list(temp[:, 0])\n",
    "    #label_list = list(temp[:, 1])\n",
    "    #label_list = [int(i) for i in label_list]\n",
    "    image_list=[]\n",
    "    label_list=[]\n",
    "    \n",
    "    with open('F:/Udacity ML/git/udacity-capstone/images10.csv') as f:\n",
    "        reader = csv.reader(f,delimiter=',')\n",
    "        for row in reader:\n",
    "            #print( row[0])\n",
    "            #print (row[1])\n",
    "            #temp=literal_eval(row[0])            \n",
    "            image_list.append(row[0])\n",
    "            temp=literal_eval(row[1])            \n",
    "            label_list.append(temp)\n",
    "    print (type(image_list[0]))\n",
    "    print (type(label_list[0]))\n",
    "    ##for i in label_list:\n",
    "       # print (type(i) )     \n",
    "    #print (image_list)\n",
    "    #print (label_list)\n",
    "    return image_list, label_list\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):\n",
    "    '''\n",
    "    Args:\n",
    "        image: list type\n",
    "        label: list type\n",
    "        image_W: image width\n",
    "        image_H: image height\n",
    "        batch_size: batch size\n",
    "        capacity: the maximum elements in queue\n",
    "    Returns:\n",
    "        image_batch: 4D tensor [batch_size, width, height, 3], dtype=tf.float32\n",
    "        label_batch: 1D tensor [batch_size], dtype=tf.int32\n",
    "    '''\n",
    "    \n",
    "    print (\"Hello\")\n",
    "    print (type(image[0]))\n",
    "    print (type(label[0]))\n",
    "    print (image)\n",
    "    print (label)\n",
    "    image = tf.cast(image, tf.string)#cast image list values to string tensors\n",
    "    label = tf.to_int32(label)\n",
    "    #print (type(image))\n",
    "    #print (type(label))\n",
    "\n",
    "\n",
    "    # make an input queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    "    \n",
    "    label = input_queue[1]\n",
    "    #print(input_queue[0])\n",
    "    #print (input_queue[1])\n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "    \n",
    "    ######################################\n",
    "    # data argumentation should go to here\n",
    "    ######################################\n",
    "    \n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)\n",
    "    \n",
    "    # if you want to test the generated batches of images, you might want to comment the following line.\n",
    "    # 如果想看到正常的图片，请注释掉111行（标准化）和 126行（image_batch = tf.cast(image_batch, tf.float32)）\n",
    "    # 训练时不要注释掉！\n",
    "    #image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                                batch_size= batch_size,\n",
    "                                                num_threads= 2, \n",
    "                                                capacity = capacity)\n",
    "    \n",
    "    #you can also use shuffle_batch \n",
    "#    image_batch, label_batch = tf.train.shuffle_batch([image,label],\n",
    "#                                                      batch_size=BATCH_SIZE,\n",
    "#                                                      num_threads=64,\n",
    "#                                                      capacity=CAPACITY,\n",
    "#                                                      min_after_dequeue=CAPACITY-1)\n",
    "    \n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    #image_batch = tf.cast(image_batch, tf.float32)\n",
    "    \n",
    "    return image_batch, label_batch\n",
    "\n",
    "\n",
    " \n",
    "#TEST\n",
    "# To test the generated batches of images\n",
    "# When training the model, DO comment the following codes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "CAPACITY = 10\n",
    "IMG_W = 512\n",
    "IMG_H = 512\n",
    "\n",
    "\n",
    "image_list, label_list = get_files()\n",
    "image_batch, label_batch = get_batch(image_list, label_list, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    i = 0\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    try:\n",
    "        while not coord.should_stop() and i<1:\n",
    "            \n",
    "            img, label = sess.run([image_batch, label_batch])\n",
    "            \n",
    "            # just test one batch\n",
    "            for j in np.arange(BATCH_SIZE):\n",
    "                print('label: %d' %label[j])\n",
    "                plt.imshow(img[j,:,:,:])\n",
    "                plt.show()\n",
    "            i+=1\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done!')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
