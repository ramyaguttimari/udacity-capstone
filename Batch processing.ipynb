{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Diabetic Retinopathy Detection\n",
    "In this project, classification of retinal images for the presence of diabetic retinopathy is done.The dataset is taken from the kaggle competition (https://www.kaggle.com/c/diabetic-retinopathy-detection).Run the following cell to load files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import isfile,isdir\n",
    "import glob\n",
    "import os\n",
    "from PIL import ImageEnhance\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ='/Users/hmakam200/Desktop/ramya_data/sample_images/onlyImage/onlyImage.csv'\n",
    "#import csv\n",
    "#images=[]\n",
    "#for file in glob.glob(\"F:/Diabetic Retinopathy/TrainDataPreProcessed/FinalData/*.jpeg\"):\n",
    " #   im=Image.open(file)\n",
    "    #arr=list(im.getdata())\n",
    "    #images.append(arr)\n",
    "    #im.close()\n",
    "#sort the labels file using image as value\n",
    "#labels=pd.read_csv(\"F:/Diabetic Retinopathy/labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data=pickle.load(open(\"F:/Udacity ML/git/machine-learning/projects/image-classification/preprocess_batch_5.p\",\"rb\"))\n",
    "print (data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r array - one dimensional\n",
      "0.0\n",
      "10.0\n",
      "Raw data - 2 dimensional\n",
      "[ 0.  0.  0.  0.]\n",
      "[ 90.  90.  90.  90.]\n",
      "(100003, 4)\n",
      "raw target - 2 dimensional\n",
      "[1 0 0]\n",
      "[1 0 0]\n",
      "(100003, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#http://ischlag.github.io/2016/11/07/tensorflow-input-pipeline-for-large-datasets/\n",
    "#Loading data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "r=np.arange(0.0,100003.0)\n",
    "print(\"r array - one dimensional\")\n",
    "print (r[0])\n",
    "print (r[10])\n",
    "raw_data=np.dstack((r,r,r,r))[0]\n",
    "print (\"Raw data - 2 dimensional\")\n",
    "print (raw_data[0])\n",
    "print (raw_data[90])\n",
    "print (raw_data.shape)\n",
    "print (\"raw target - 2 dimensional\")\n",
    "raw_target=np.array([[1,0,0]]*100003)\n",
    "print (raw_target[0])\n",
    "print (raw_target[90])\n",
    "print(raw_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a FIFO Queue\n",
    "\n",
    "\n",
    "queue_input_data=tf.placeholder(tf.float32,shape=[20,4])\n",
    "queue_input_target=tf.placeholder(tf.float32,shape=[20,3])\n",
    "\n",
    "\n",
    "queue=tf.FIFOQueue(capacity=50,dtypes=[tf.float32,tf.float32],shapes=[[4],[3]])\n",
    "\n",
    "enqueue_op=queue.enqueue_many([queue_input_data,queue_input_target])\n",
    "dequeue_op=queue.dequeue()\n",
    "\n",
    "#Now we can already continue building our input pipeline.\n",
    "#After performing some preprocessing on the dequeued data \n",
    "#we can group them into a batch and use a session in order to draw the next batch of samples from our input pipeline.\n",
    "#But before we can do that,\n",
    "#we have to start a thread that will fill our queue object by calling queue.enqueue_many with data from our numpy data. \n",
    "#Here, instead of reading from our simple numpy data array\n",
    "#you could also access a database, a network source, or a big file which you cannot load fully into memory.\n",
    "#Notice that I loop endlessly in order to keep up a stream of incoming data.\n",
    "#Donâ€™t worry about shuffeling here you can use tf.train.shuffle_batch instead of tf.train.batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tensorflow recommendation \n",
    "#capacity=min_after_dequeue+(num_threads + a small safety margin)*batch_size\n",
    "data_batch,target_batch=tf.train.shuffle_batch(dequeue_op,batch_size=15,capacity=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to write into queue\n",
      "try to enqueue  0  to  20\n",
      "added to the queue\n",
      "starting to write into queue\n",
      "try to enqueue  20  to  40\n",
      "added to the queue\n",
      "starting to write into queue\n",
      "try to enqueue  40  to  60\n",
      "added to the queue\n",
      "starting to write into queue\n",
      "try to enqueue  60  to  80\n",
      "added to the queue\n",
      "starting to write into queue\n",
      "try to enqueue  80  to  100\n"
     ]
    }
   ],
   "source": [
    "#start the threads\n",
    "#Now the only thing that is missing are the queue runner threads for our tf.train.batch.\n",
    "def enqueue(sess):\n",
    "    under = 0\n",
    "    max = len(raw_data)\n",
    "    while True:\n",
    "        print(\"starting to write into queue\")\n",
    "        upper = under + 20\n",
    "        print(\"try to enqueue \", under, \" to \", upper)\n",
    "        if upper <= max:\n",
    "            curr_data = raw_data[under:upper]\n",
    "            curr_target = raw_target[under:upper]\n",
    "            under = upper\n",
    "        else:\n",
    "            rest = upper - max\n",
    "            curr_data = np.concatenate((raw_data[under:max], raw_data[0:rest]))\n",
    "            curr_target = np.concatenate((raw_target[under:max], raw_target[0:rest]))\n",
    "            under = rest\n",
    "            \n",
    "        sess.run(enqueue_op, feed_dict={queue_input_data: curr_data,queue_input_target: curr_target})\n",
    "        print(\"added to the queue\")\n",
    "    print(\"finished enqueueing\")\n",
    "\n",
    "sess = tf.Session()\n",
    "enqueue_thread = threading.Thread(target=enqueue, args=[sess])\n",
    "enqueue_thread.isDaemon()\n",
    "enqueue_thread.start()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.]\n",
      " [  1.   1.   1.   1.]\n",
      " [  2.   2.   2.   2.]\n",
      " [  3.   3.   3.   3.]\n",
      " [  4.   4.   4.   4.]\n",
      " [  5.   5.   5.   5.]\n",
      " [  6.   6.   6.   6.]\n",
      " [  7.   7.   7.   7.]\n",
      " [  8.   8.   8.   8.]\n",
      " [  9.   9.   9.   9.]\n",
      " [ 10.  10.  10.  10.]\n",
      " [ 11.  11.  11.  11.]\n",
      " [ 12.  12.  12.  12.]\n",
      " [ 13.  13.  13.  13.]\n",
      " [ 14.  14.  14.  14.]]\n",
      "added to the queue\n",
      "starting to write into queue\n",
      "try to enqueue  100  to  120\n"
     ]
    }
   ],
   "source": [
    "#Now, the next batch for our model should be ready and already waiting for us. All we have to do is the following. \n",
    "#The run_options are not necessary but will produce a timeout in case something went wrong beforehand.\n",
    "run_options=tf.RunOptions(timeout_in_ms=4000)\n",
    "curr_data_batch,curr_target_batch=sess.run([data_batch,target_batch],options=run_options)\n",
    "print(curr_data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1139, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1121, in _run_fn\n",
      "    status, run_metadata)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n",
      "    pywrap_tensorflow.TF_GetCode(status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_1_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue_1, _arg_Placeholder_4_0_0, _arg_Placeholder_5_0_1)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-33-5c59260dc5ff>\", line 20, in enqueue\n",
      "    sess.run(enqueue_op, feed_dict={queue_input_data: curr_data,queue_input_target: curr_target})\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 789, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 997, in _run\n",
      "    feed_dict_string, options, run_metadata)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1132, in _do_run\n",
      "    target_list, options, run_metadata)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_1_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue_1, _arg_Placeholder_4_0_0, _arg_Placeholder_5_0_1)]]\n",
      "\n",
      "Caused by op 'fifo_queue_1_EnqueueMany', defined at:\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-24-6201c5d31585>\", line 10, in <module>\n",
      "    enqueue_op=queue.enqueue_many([queue_input_data,queue_input_target])\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 366, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 1162, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"C:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_1_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue_1, _arg_Placeholder_4_0_0, _arg_Placeholder_5_0_1)]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Once we are done with our input pipeline we should stop all running threads before closing the session.\n",
    "sess.run(queue.close(cancel_pending_enqueues=True))\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()\n",
    "#When you run this script and close the queue in the end it is possible that you get Enqueue operation was cancelled errors.\n",
    "#This has to do with closing the queues while some threads still seem to be operating.\n",
    "#However, if you do it like this no threads will survive and use up your GPU memory.\n",
    "#If you run into weird CUDA memory errors,\n",
    "#have a look at the running processes and make sure there is no zombie thread from your last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from numpy import linalg as LA\n",
    "    \n",
    "    x=x/255\n",
    "    return x\n",
    "for im in images:\n",
    "    im=normalize(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since we have imbalanced data, we use SMOTE algorithm to over sample the training data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm=SMOTE(random_state=12,ratio=0.1)\n",
    "X_train_res,y_train_res=sm.fit_sample(X_train,y_train)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
