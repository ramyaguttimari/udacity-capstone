{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from numpy import linalg as LA\n",
    "    print (x.shape)\n",
    "    x=x/255\n",
    "    print (x.shape)\n",
    "    return x\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "map=[0,1]\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from sklearn import preprocessing\n",
    "    lb=preprocessing.LabelBinarizer()\n",
    "    lb.fit(map)\n",
    "    \n",
    "    return lb.transform(x)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "batch_size = 2\n",
    "keep_probability = 0.9\n",
    "read_threads=1\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    t=tf.placeholder(tf.float32,shape=[None,image_shape[0],image_shape[1],image_shape[2]],name='x')\n",
    "    return t\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    t=tf.placeholder(tf.int32,shape=[None,n_classes],name='y')\n",
    "    return t\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    t=tf.placeholder(tf.float32,name='keep_prob')\n",
    "    return t\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from math import sqrt\n",
    "    batch_size,dim1,dim2,dim3=x_tensor.get_shape().as_list()\n",
    "    filter_weights=tf.Variable(tf.truncated_normal(list(conv_ksize)+[x_tensor.get_shape().as_list()[-1]]+[conv_num_outputs],stddev=0.1))\n",
    "    filter_bias=tf.Variable(tf.zeros(conv_num_outputs,dtype=tf.float32))\n",
    "    strides=[1]+list(conv_strides)+[1]\n",
    "    padding='SAME'\n",
    "    conv=tf.nn.conv2d(x_tensor,filter_weights,strides,padding)\n",
    "    conv=tf.nn.bias_add(conv,filter_bias)\n",
    "    conv=tf.nn.relu(conv)\n",
    "    \n",
    "    return tf.nn.max_pool(conv,ksize=[1]+list(pool_ksize)+[1],strides=[1]+list(pool_strides)+[1],padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size,dim1,dim2,dim3=x_tensor.get_shape().as_list()\n",
    "    newdim=dim1*dim2*dim3\n",
    "    return tf.reshape(x_tensor,[-1,newdim])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from math import sqrt\n",
    "    num_features=x_tensor.shape[1].value\n",
    "    weights=tf.Variable(tf.truncated_normal([num_features]+[num_outputs],stddev=0.1))\n",
    "    bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    con=tf.matmul(x_tensor,weights)\n",
    "    con=tf.add(con,bias)\n",
    "    con=tf.nn.relu(con)\n",
    "    \n",
    "    \n",
    "    return con\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weights=tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1]]+[num_outputs],stddev=0.1))\n",
    "    bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    out=tf.matmul(x_tensor,weights)\n",
    "    out=tf.add(out,bias)\n",
    "    \n",
    "    return out\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    con1=conv2d_maxpool(x,8,(4,4),(1,1),(2,2),(2,2))\n",
    "    con1=conv2d_maxpool(con1,16,(4,4),(1,1),(2,2),(2,2))\n",
    "    \n",
    "    con1=conv2d_maxpool(con1,32,(4,4),(1,1),(2,2),(2,2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat=flatten(con1)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    fc1=fully_conn(flat,1024)    \n",
    "    fc1=tf.nn.dropout(fc1,keep_prob)\n",
    "    fc1=fully_conn(fc1,1024)\n",
    "    fc1=tf.nn.dropout(fc1,keep_prob)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    fc1=output(fc1,2)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return fc1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#tests.test_conv_net(conv_net)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, image_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(cost,feed_dict={x:image_batch,y:label_batch,keep_prob:keep_probability})\n",
    "    session.run(optimizer,feed_dict={x:image_batch,y:label_batch,keep_prob:keep_probability})\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def print_stats(session, image_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss=session.run(cost,feed_dict={x:image_batch,y:label_batch,keep_prob: 1.0})\n",
    "    acc=session.run(accuracy,feed_dict={x:valid_features,y:valid_labels,keep_prob:1.0})\n",
    "    print('loss',loss)\n",
    "    print('accuracy',acc)\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Second method called for batching\n",
    "def read_my_file_format(filename_queue):\n",
    "        reader = tf.TextLineReader()\n",
    "        key, record_string = reader.read(filename_queue)\n",
    "        # \"a\" means representative value to indicate type for csv cell value.\n",
    "        image_file_name, label = tf.decode_csv(record_string, [[\"a\"], [0]])\n",
    "\n",
    "        image_jpeg_data = tf.read_file(image_file_name)\n",
    "        #depth_png_data = tf.read_file(depth_file_name)\n",
    "        # channels=1 means image is read as gray-scale\n",
    "        image_decoded = tf.image.decode_jpeg(image_jpeg_data, channels=3)\n",
    "        \n",
    "        #some preprocessing on images can be done\n",
    "        # Randomly crop a [height, width] section of the image.\n",
    "        distorted_image = tf.random_crop(image_decoded, [512, 512, 3])\n",
    "        # Randomly flip the image horizontally.\n",
    "        distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "        distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "        distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "        image_decoded = tf.image.per_image_standardization(image_decoded)\n",
    "        image_decoded.set_shape([512, 512, 3])\n",
    "\n",
    "\n",
    "        # Subtract off the mean and divide by the variance of the pixels.\n",
    "\n",
    "        #depth_decoded = tf.image.decode_png(depth_png_data, channels=3)\n",
    "        #depth_decoded.set_shape([640, 640, 1])\n",
    "        return image_decoded, label\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#first method to call for batching\n",
    "def input_pipeline(filenames, batch_size, read_threads, num_epochs=None):\n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=True)\n",
    "        min_after_dequeue = 2\n",
    "        capacity = min_after_dequeue + 3 * batch_size\n",
    "\n",
    "        example_list = [read_my_file_format(filename_queue) for _ in range(read_threads)]\n",
    "        example_batch, label_batch = tf.train.shuffle_batch_join(\n",
    "            example_list, batch_size=batch_size, capacity=capacity,\n",
    "            min_after_dequeue=min_after_dequeue)\n",
    "        return example_batch, label_batch\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def prepare_batch():\n",
    "        # image_batch, depth_batch : Tensor(\"shuffle_batch_join_14:0\", shape=(batch_size, 640, 640, 1), dtype=uint8)\n",
    "        image_batch, label_batch = input_pipeline(['images10.csv'], batch_size, read_threads)\n",
    "        \n",
    "        return image_batch,label_batch\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((512, 512, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Learning loop\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a75c93ddd080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel_data\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnLoop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\OM\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m             raise TypeError('The value of a feed cannot be a tf.Tensor object. '\n\u001b[0m\u001b[0;32m    949\u001b[0m                             \u001b[1;34m'Acceptable feed values include Python scalars, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m                             'strings, lists, numpy ndarrays, or TensorHandles.')\n",
      "\u001b[1;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles."
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "i = 0\n",
    "nLoop = 100 # 200\n",
    "print(\"Start Learning loop\")\n",
    "epoch_counter=100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            i += 1\n",
    "            \n",
    "            image_data, label_data = prepare_batch()\n",
    "            sess.run(optimizer,feed_dict={x:image_data, y:label_data })\n",
    "            if i == nLoop:\n",
    "                coord.request_stop()\n",
    "\n",
    "           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training')\n",
    "        coord.request_stop(e)\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "    # stop our queue threads and properly close the session\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
