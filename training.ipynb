{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import model\n",
    "\n",
    "#%%\n",
    "\n",
    "N_CLASSES = 2\n",
    "IMG_W = 208  # resize the image, if the input image is too large, training will be very slow.\n",
    "IMG_H = 208\n",
    "BATCH_SIZE = 16\n",
    "CAPACITY = 2000\n",
    "MAX_STEP = 10000 # with current parameters, it is suggested to use MAX_STEP>10k\n",
    "learning_rate = 0.0001 # with current parameters, it is suggested to use learning rate<0.0001\n",
    "\n",
    "\n",
    "#%%\n",
    "def run_training():\n",
    "    \n",
    "    # you need to change the directories to yours.\n",
    "    train_dir = '/home/kevin/tensorflow/cats_vs_dogs/data/train/'\n",
    "    logs_train_dir = '/home/kevin/tensorflow/cats_vs_dogs/logs/train/'\n",
    "    \n",
    "    train, train_label = input_data.get_files(train_dir)\n",
    "    \n",
    "    train_batch, train_label_batch = input_data.get_batch(train,\n",
    "                                                          train_label,\n",
    "                                                          IMG_W,\n",
    "                                                          IMG_H,\n",
    "                                                          BATCH_SIZE, \n",
    "                                                          CAPACITY)      \n",
    "    train_logits = model.inference(train_batch, BATCH_SIZE, N_CLASSES)\n",
    "    train_loss = model.losses(train_logits, train_label_batch)        \n",
    "    train_op = model.trainning(train_loss, learning_rate)\n",
    "    train__acc = model.evaluation(train_logits, train_label_batch)\n",
    "       \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    sess = tf.Session()\n",
    "    train_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    try:\n",
    "        for step in np.arange(MAX_STEP):\n",
    "            if coord.should_stop():\n",
    "                    break\n",
    "            _, tra_loss, tra_acc = sess.run([train_op, train_loss, train__acc])\n",
    "               \n",
    "            if step % 50 == 0:\n",
    "                print('Step %d, train loss = %.2f, train accuracy = %.2f%%' %(step, tra_loss, tra_acc*100.0))\n",
    "                summary_str = sess.run(summary_op)\n",
    "                train_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            if step % 2000 == 0 or (step + 1) == MAX_STEP:\n",
    "                checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "    \n",
    "\n",
    "#%% Evaluate one image\n",
    "# when training, comment the following codes.\n",
    "\n",
    "\n",
    "#from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "#\n",
    "#def get_one_image(train):\n",
    "#    '''Randomly pick one image from training data\n",
    "#    Return: ndarray\n",
    "#    '''\n",
    "#    n = len(train)\n",
    "#    ind = np.random.randint(0, n)\n",
    "#    img_dir = train[ind]\n",
    "#\n",
    "#    image = Image.open(img_dir)\n",
    "#    plt.imshow(image)\n",
    "#    image = image.resize([208, 208])\n",
    "#    image = np.array(image)\n",
    "#    return image\n",
    "#\n",
    "#def evaluate_one_image():\n",
    "#    '''Test one image against the saved models and parameters\n",
    "#    '''\n",
    "#    \n",
    "#    # you need to change the directories to yours.\n",
    "#    train_dir = '/home/kevin/tensorflow/cats_vs_dogs/data/train/'\n",
    "#    train, train_label = input_data.get_files(train_dir)\n",
    "#    image_array = get_one_image(train)\n",
    "#    \n",
    "#    with tf.Graph().as_default():\n",
    "#        BATCH_SIZE = 1\n",
    "#        N_CLASSES = 2\n",
    "#        \n",
    "#        image = tf.cast(image_array, tf.float32)\n",
    "#        image = tf.image.per_image_standardization(image)\n",
    "#        image = tf.reshape(image, [1, 208, 208, 3])\n",
    "#        logit = model.inference(image, BATCH_SIZE, N_CLASSES)\n",
    "#        \n",
    "#        logit = tf.nn.softmax(logit)\n",
    "#        \n",
    "#        x = tf.placeholder(tf.float32, shape=[208, 208, 3])\n",
    "#        \n",
    "#        # you need to change the directories to yours.\n",
    "#        logs_train_dir = '/home/kevin/tensorflow/cats_vs_dogs/logs/train/' \n",
    "#                       \n",
    "#        saver = tf.train.Saver()\n",
    "#        \n",
    "#        with tf.Session() as sess:\n",
    "#            \n",
    "#            print(\"Reading checkpoints...\")\n",
    "#            ckpt = tf.train.get_checkpoint_state(logs_train_dir)\n",
    "#            if ckpt and ckpt.model_checkpoint_path:\n",
    "#                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "#                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "#                print('Loading success, global_step is %s' % global_step)\n",
    "#            else:\n",
    "#                print('No checkpoint file found')\n",
    "#            \n",
    "#            prediction = sess.run(logit, feed_dict={x: image_array})\n",
    "#            max_index = np.argmax(prediction)\n",
    "#            if max_index==0:\n",
    "#                print('This is a cat with possibility %.6f' %prediction[:, 0])\n",
    "#            else:\n",
    "#                print('This is a dog with possibility %.6f' %prediction[:, 1])\n",
    "\n",
    "\n",
    "#%%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
